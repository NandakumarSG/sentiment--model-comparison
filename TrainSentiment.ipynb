{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "TrainSentiment.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "[View in Colaboratory](https://colab.research.google.com/github/NandakumarSG/sentiment--model-comparison/blob/master/TrainSentiment.ipynb)"
      ]
    },
    {
      "metadata": {
        "id": "GB3HG4YLttCS",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#importing all the necessary libraries\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "%matplotlib inline\n",
        "import string\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import confusion_matrix, classification_report\n",
        "from sklearn.svm import SVC"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "c6yT3nIVrJU-",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Downloading the yelp dataset. I used a shortened url of the dataset available in kaggle. The dataset is the mirror of the original yelp dataset. https://www.kaggle.com/yelp-dataset/yelp-dataset/version/6"
      ]
    },
    {
      "metadata": {
        "id": "_2RgH_rH7Rwn",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 315
        },
        "outputId": "d3b8d5ff-31e4-478d-fff2-5365f4297c6e"
      },
      "cell_type": "code",
      "source": [
        "!wget https://bit.ly/2MYY1Ka"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2018-06-25 07:03:04--  https://bit.ly/2MYY1Ka\r\n",
            "Resolving bit.ly (bit.ly)... 67.199.248.10, 67.199.248.11\n",
            "Connecting to bit.ly (bit.ly)|67.199.248.10|:443... connected.\n",
            "HTTP request sent, awaiting response... 301 Moved Permanently\n",
            "Location: https://storage.googleapis.com/kaggle-datasets/10100/16731/yelp-dataset.zip?GoogleAccessId=web-data@kaggle-161607.iam.gserviceaccount.com&Expires=1530169345&Signature=jysNlBleGOh6qqscOkQW3MlOC6FunmLufopX2eOaGpGZCO/VBHZvcRx/Opf4u2HJm5TPZFhK4VXwfFjgkanjM3CHxg4B8VQuPOryO8ho6pe%2BGEjNE3dycHGxfk5ebYLZ/NZD761oprv%2BS3pikSL89uE67P5wEZ4iL4nApmDCR%2B0kxWuromCVE5DtXmNDjgJkt5JdNYe82z61WYdNerhH%2BoOPF0DQmxcd%2B7BJOUeBj6E5ZD500p6OALf78CfB2PO8fZMAMjR5tVTe/3aHcHpw94BdloApWKI3XFqBwN6OySkocgLVSLHyhksvC8i1ylX/zWbebEASvoGsfb7VnLgJDg%3D%3D [following]\n",
            "--2018-06-25 07:03:04--  https://storage.googleapis.com/kaggle-datasets/10100/16731/yelp-dataset.zip?GoogleAccessId=web-data@kaggle-161607.iam.gserviceaccount.com&Expires=1530169345&Signature=jysNlBleGOh6qqscOkQW3MlOC6FunmLufopX2eOaGpGZCO/VBHZvcRx/Opf4u2HJm5TPZFhK4VXwfFjgkanjM3CHxg4B8VQuPOryO8ho6pe%2BGEjNE3dycHGxfk5ebYLZ/NZD761oprv%2BS3pikSL89uE67P5wEZ4iL4nApmDCR%2B0kxWuromCVE5DtXmNDjgJkt5JdNYe82z61WYdNerhH%2BoOPF0DQmxcd%2B7BJOUeBj6E5ZD500p6OALf78CfB2PO8fZMAMjR5tVTe/3aHcHpw94BdloApWKI3XFqBwN6OySkocgLVSLHyhksvC8i1ylX/zWbebEASvoGsfb7VnLgJDg%3D%3D\n",
            "Resolving storage.googleapis.com (storage.googleapis.com)... 173.194.203.128, 2607:f8b0:400e:c03::80\n",
            "Connecting to storage.googleapis.com (storage.googleapis.com)|173.194.203.128|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 2693840057 (2.5G) [application/zip]\n",
            "Saving to: ‘2MYY1Ka’\n",
            "\n",
            "2MYY1Ka              58%[==========>         ]   1.47G  86.5MB/s    eta 8s     "
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "2MYY1Ka             100%[===================>]   2.51G  17.1MB/s    in 59s     \n",
            "\n",
            "2018-06-25 07:04:03 (43.8 MB/s) - ‘2MYY1Ka’ saved [2693840057/2693840057]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "H6zC2rdB7gVX",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 173
        },
        "outputId": "ace8f753-bb50-42b3-d9a8-81bd1bb95145"
      },
      "cell_type": "code",
      "source": [
        "!unzip 2MYY1Ka"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Archive:  2MYY1Ka\n",
            "  inflating: yelp_business.csv       \n",
            "  inflating: yelp_checkin.csv        \n",
            "  inflating: Dataset_Challenge_Dataset_Agreement.pdf  \n",
            "  inflating: yelp_tip.csv            \n",
            "  inflating: yelp_business_attributes.csv  \n",
            "  inflating: yelp_review.csv         \n",
            "  inflating: yelp_user.csv           \n",
            "  inflating: yelp_business_hours.csv  \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "RCd80mSRBVx9",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1007
        },
        "outputId": "b3ca4014-0bfc-4fb5-b192-40ee308358f0"
      },
      "cell_type": "code",
      "source": [
        "nltk.download()#downloading stopwords. d=>Identifier==>popular should do the trick"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "NLTK Downloader\n",
            "---------------------------------------------------------------------------\n",
            "    d) Download   l) List    u) Update   c) Config   h) Help   q) Quit\n",
            "---------------------------------------------------------------------------\n",
            "Downloader> d\n",
            "\n",
            "Download which package (l=list; x=cancel)?\n",
            "  Identifier> popular\n",
            "    Downloading collection 'popular'\n",
            "       | \n",
            "       | Downloading package cmudict to /content/nltk_data...\n",
            "       |   Unzipping corpora/cmudict.zip.\n",
            "       | Downloading package gazetteers to /content/nltk_data...\n",
            "       |   Unzipping corpora/gazetteers.zip.\n",
            "       | Downloading package genesis to /content/nltk_data...\n",
            "       |   Unzipping corpora/genesis.zip.\n",
            "       | Downloading package gutenberg to /content/nltk_data...\n",
            "       |   Unzipping corpora/gutenberg.zip.\n",
            "       | Downloading package inaugural to /content/nltk_data...\n",
            "       |   Unzipping corpora/inaugural.zip.\n",
            "       | Downloading package movie_reviews to /content/nltk_data...\n",
            "       |   Unzipping corpora/movie_reviews.zip.\n",
            "       | Downloading package names to /content/nltk_data...\n",
            "       |   Unzipping corpora/names.zip.\n",
            "       | Downloading package shakespeare to /content/nltk_data...\n",
            "       |   Unzipping corpora/shakespeare.zip.\n",
            "       | Downloading package stopwords to /content/nltk_data...\n",
            "       |   Unzipping corpora/stopwords.zip.\n",
            "       | Downloading package treebank to /content/nltk_data...\n",
            "       |   Unzipping corpora/treebank.zip.\n",
            "       | Downloading package twitter_samples to /content/nltk_data...\n",
            "       |   Unzipping corpora/twitter_samples.zip.\n",
            "       | Downloading package omw to /content/nltk_data...\n",
            "       |   Unzipping corpora/omw.zip.\n",
            "       | Downloading package wordnet to /content/nltk_data...\n",
            "       |   Unzipping corpora/wordnet.zip.\n",
            "       | Downloading package wordnet_ic to /content/nltk_data...\n",
            "       |   Unzipping corpora/wordnet_ic.zip.\n",
            "       | Downloading package words to /content/nltk_data...\n",
            "       |   Unzipping corpora/words.zip.\n",
            "       | Downloading package maxent_ne_chunker to\n",
            "       |     /content/nltk_data...\n",
            "       |   Unzipping chunkers/maxent_ne_chunker.zip.\n",
            "       | Downloading package punkt to /content/nltk_data...\n",
            "       |   Unzipping tokenizers/punkt.zip.\n",
            "       | Downloading package snowball_data to /content/nltk_data...\n",
            "       | Downloading package averaged_perceptron_tagger to\n",
            "       |     /content/nltk_data...\n",
            "       |   Unzipping taggers/averaged_perceptron_tagger.zip.\n",
            "       | \n",
            "     Done downloading collection popular\n",
            "\n",
            "---------------------------------------------------------------------------\n",
            "    d) Download   l) List    u) Update   c) Config   h) Help   q) Quit\n",
            "---------------------------------------------------------------------------\n",
            "Downloader> q\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "metadata": {
        "id": "__dDX209tu-K",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def text_process(text):\n",
        "\n",
        "    '''\n",
        "    Takes in a string of text, then performs the following:\n",
        "    1. Remove all punctuation\n",
        "    2. Remove all stopwords\n",
        "    3. Return the cleaned text as a list of words\n",
        "    '''\n",
        "    nopunc = [char for char in text if char not in string.punctuation]\n",
        "    nopunc = ''.join(nopunc)\n",
        "    return [word for word in nopunc.split() if word.lower() not in stopwords.words('english')]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "mIEtvPmwSdXz",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "yelp = pd.read_csv('yelp_review.csv')\n",
        "yelp_class = yelp[(yelp['stars'] == 1) | (yelp['stars'] == 5)]\n",
        "yelp_new=yelp_class[0:100000]\n",
        "yelp_class=yelp_new\n",
        "X = yelp_class['text']\n",
        "y = yelp_class['stars']\n",
        "bow_transformer = TfidfVectorizer(analyzer=text_process).fit(X)\n",
        "X = bow_transformer.transform(X)\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=101)\n",
        "nb = SVC(kernel='linear')\n",
        "nb.fit(X_train, y_train)\n",
        "preds = nb.predict(X_test)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "3H3tBrO5GFkT",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 139
        },
        "outputId": "7e2eb9ab-e3b2-4a55-c659-d88124e103bf"
      },
      "cell_type": "code",
      "source": [
        "print(classification_report(y_test, preds))\n"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "             precision    recall  f1-score   support\n",
            "\n",
            "          1       0.86      0.88      0.87      7327\n",
            "          5       0.96      0.95      0.96     22673\n",
            "\n",
            "avg / total       0.94      0.94      0.94     30000\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "sM7_Kk-IGaaK",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "outputId": "87dbcbcb-5b5d-467b-90fe-573631f184dd"
      },
      "cell_type": "code",
      "source": [
        "import pickle\n",
        "filename = 'finalized_model.sav'\n",
        "pickle.dump(nb, open(filename, 'wb'))"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "metadata": {
        "id": "nI58okAwGl-R",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "outputId": "88ca0b97-151f-4355-a1b8-e21005d2ae16"
      },
      "cell_type": "code",
      "source": [
        "from google.colab import files\n"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "metadata": {
        "id": "NR3BKeaxIPSJ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "outputId": "9f3a352b-8839-4062-f01c-781ab2bb8ea1"
      },
      "cell_type": "code",
      "source": [
        "files.download('finalized_model.sav')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "X4TxOx1Q3tv-",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 121
        },
        "outputId": "ec30bd48-0626-401f-9995-4a3e8ecebe01"
      },
      "cell_type": "code",
      "source": [
        "!ls"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2I8MELW\t\t\t\t\t yelp_business_hours.csv\r\n",
            "datalab\t\t\t\t\t yelp_checkin.csv\r\n",
            "Dataset_Challenge_Dataset_Agreement.pdf  yelp_review.csv\r\n",
            "nltk_data\t\t\t\t yelp_tip.csv\r\n",
            "yelp_business_attributes.csv\t\t yelp_user.csv\r\n",
            "yelp_business.csv\r\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "bhQzS-lSEBJX",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}